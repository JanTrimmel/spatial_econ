---
title: "Spatial Economics -- Assignment 3"
author:
  - "Gustav Pirich (h11910449)"
  - "Gabriel Konecny (h11775903)"
date: "April 2, 2024"
output:
  pdf_document:
    toc: true
    includes:
      in_header: !expr file.path("~/Desktop/GITHUB/spatial_econ/helper/wraper_code.tex")
bibliography: references.bib
nocite: '@*'
header-includes:
  - \usepackage{tcolorbox}
  - \usepackage[default]{lato}
  - \usepackage{rotating}
papersize: a4
geometry: margin=2cm
urlcolor: DarkOrchid!65!black
---


```{r, setup, include = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(showtext)
showtext_auto()

pacman::p_load(spatialreg, fixest, splm, stringi, stringr, stringdist, haven, sf, dplyr, fuzzyjoin, 
               comparator, digest, zoomerjoin, ggplot2, tidyr, ggthemes, viridis, 
               fixest, conleyreg, plm, stargazer, magrittr, tidyverse, tmap, spdep, SDPDmod,
               igraph, generics, knitr, kableExtra, formatR,readxl, haven)
```

\vspace{2em}

\begin{tcolorbox}
\centering \itshape The code that was used in compiling the assignment is available on GitHub at \url{https://github.com/gustavpirich/spatial_econ/blob/main/03_assignment/03_assignmnet.Rmd}.
\end{tcolorbox}

\newpage


# Exercise A
```{r, echo=FALSE}
cigar_states <- st_read(file.path("data","cigarettes","cigar_states.xls"))
cigarette_2var <- readxl::read_excel(file.path("data","cigarettes","cigarette+2var.xls")) %>%
                        relocate(state, .before=year) 

test <- cbind(cigar_states, cigarette_2var[,"state"])[,"Name"]

data <- cigarette_2var[c("state", "year", "logc", "logp","logy")] %>%
        mutate(state = cbind(cigar_states, cigarette_2var[,"state"])[,"Name"])
W_vega <- as.matrix(readxl::read_excel(file.path("data","cigarettes","W_vega.xls"), col_names=FALSE), dimnames=FALSE)

W.adj <- as.matrix(readxl::read_excel(file.path("data","cigarettes","Spat-Sym-US.xls"), col_names=FALSE), dimnames=FALSE)
# <- nb2listw(W.adj,style="W")

scale <- function(x){
  x/sum(x)
}
W <- t(apply(W.adj,1,scale))
lW <- mat2listw(W, style="W")
#lW <- mat2listw(W.adj)
```

 Estimate the demand model, and test for spatial dependence using the procedures discussed in class, and the provided weights matrix. Suppress any theoretical considerations
 
The demand model without spatial effects can by estimated by using the package plm:
```{r}
model1 <- plm(logc~logp+logy, data=data, model="within", effect="twoways")
summary(model1)
```

This could be also done by hand by including the dummies for both fixed effects and running OLS:
```{r}
data_big <- cigarette_2var %>%
            fastDummies::dummy_cols(select_columns = "year") %>%
            fastDummies::dummy_cols(select_columns = "state") %>%
            select(c(logc, logp,logy, starts_with("year_")|starts_with("state_")))
OLS <- lm(logc ~ ., data_big)
OLS
```

Where the point estimates of logp and logy are numerically identical to that of plm(). Thus we can see that using plm with "within" model and "twoways" effect is the way to go.

— which model would the classical specification search prefer?


```{r}
fm1 <- logc ~ logp + logy

# Spatial lag structure?
slmtest(fm1, data=data, listw=lW, test="lml", model="within", effect="twoways")

# Spatial error structure?
slmtest(fm1, data=data, listw=lW, test="lme", model="within", effect="twoways")

# Robust versions:
# Spatial lag allowing for spatial error?
slmtest(fm1, data=data, listw=lW, test="rlml", model="within", effect="twoways")

# Spatial error allowing for spatial lag?
slmtest(fm1, data=data, listw=lW, test="rlme", model="within", effect="twoways")
```

Allowing for spatial error, the spatial lag dependence is not significant. Thus this classical specification search suggests estimating SEM model. 

- Estimate the model implied by the specification search and contrast the effect estimates
with a SLX model specification:

Thus using the spml function from class, we can estimate sem model by setting the spatial lag of dependent variable to false (lag=FALSE):
```{r}
data <- data.frame(data)
sem <- spml(fm1, data, listw=lW, lag=FALSE, spatial.error = "b", 
                    model="within", effect="twoways") 
summary(sem)
```

```{r}
# # `effects()` extracts the individual FE, which are not visible in the `summary()`  
# eff <- effects(sem)
```

SLX model can be estimated by using OLS, i.e. by using plm() function from before where we include the spatially lagged values of explanatory variables:
```{r}

slx_OLS <- function(W){
W_ <- kronecker(diag(nrow(unique(cigarette_2var[,"year"]))), W)
W_logp <- W_ %*% data[,"logp"]
W_logy <- W_ %*% data[,"logy"]
data_slx <- cbind(data, W_logp, W_logy)
slx <- plm(logc~logp+logy+W_logp+W_logy, data=data_slx, model="within", effect="twoways")
return((slx))
}

```

```{r}
slx_OLS(W)
```

```{r, eval=FALSE}
# xy <- read_excel(file.path("data","cigarettes","cigar_states.xls"), col_names = TRUE)
# n_time <- nrow(unique(cigarette_2var[,"year"]))
# 
# dist <- as.matrix(dist(xy))
# diag(dist) <- Inf # Diagonal elements will be 0
# Psi <- function(delta) {
# W_dist <- dist ^ (-delta) # Build
# W_dist <- W_dist / max(eigen(W_dist, symmetric = TRUE)$values) # Scale
# kronecker <- kronecker(diag(n_time), W_dist)
# return (W_dist)
# }
# W_dist <- Psi(3)
# 

```



Again, we get results identical to those reported in Vega and Elhorst 2015.

– What could be the rationale to use the SLX model as opposed to other spatial
specifications?

The choice of the model should be based on theory. If we expect spillovers of exogenous variables and spillovers of endogenous variables or correlation of error terms is expected to be less pronounced or absent, it might be good idea to consider SLX. However, there are also reasons to consider SLX as a point of departure even if the theory is not clear about which model to choose. First, when using the SLX model, the estimation and interpretation of spillover effects is more straightforward. In contrast to endogenous models, SLX allows us to parametrize W and its parameters can be estimated. Strong limitation of SAR and SAC models is that the ratio between the spillover and direct effects of is same for every explanatory variable, which is unlikely to be true in many empirical studies. This is not the case for SLX model, where we get estimates of both by construction. Thus SLX can be considered more flexible in this perspective.

– Which type(s) of spillover(s) would you expect in the model for cigarette demand?

We would expect no endogenous spillover effects, since we dont believe that demand for cigarettes in a country should determine demand for cigarettes in neighboring country if there are no shortages. If however, the price of cigarettes in neighboring country is lower, people living near the border could be buying cigarettes in the neighboring country. This is called bootlegging effect. On other hand, if the income in our country increases, the opportunity costs of time of our citizens increase and they might then prefer to buy the more expensive cigarettes in home country instead. Thus we would expect spatially lagged exogenous variables to be relevant: An increase in price of cigarettes in neighboring country should have positive effect on the demand for cigarettes in home country. Increase in income of neighboring country should have negative effect on the demand for cigarettes in home. 

- Re-run the analysis using a SLX model with a distance decay specification (between centers) for the weights matrix, i.e. wij = 1/dγ ij following Halleck Vega and Elhorst (2015). Use a distance decay parameter of γ = 3.

For this we first create a neighbour list, where all regions are neighbors by setting the distance threshold to big enough value and then compute distances using nbdists. They are then transformed as suggested above and scaled by maximum eigenvalue as in the paper.

```{r}
coords <- cigar_states[,2:3]

decay <- function(gamma){
distw <- dnearneigh(coords, 0, 999999, row.names=cigar_states$Name, longlat=FALSE)
dists <- nbdists(distw, coords, longlat=FALSE)
ids <- lapply(dists, function(x) lapply(x, function(y) 1/(y^gamma)))
lWd <- nb2listw(distw, glist = ids, style = "B",zero.policy=TRUE)
Wd1 <- listw2mat(lWd)
Wd <- Wd1 / max(abs(eigen(Wd1)$values))
return(Wd)
}
Wd <- decay(3) 
colnames(Wd) <- rownames(Wd)
```

Using gamma similar to the paper, we get coefficient estimates which are very close to thsoe in the paper.
```{r}
summary(slx_OLS(Wd))
```


– Describe the network recovered by Halleck Vega and Elhorst (2015):
```{r}
distw
46*46-46
(46*46-46)/46*46
```

In this network all agents are connected, only the weights differ - which are given by the distance decay formula above. This corresponds to average number of links being 45 i.e. all regions except the region itself. Thus the percentage of nonzero weights simply gives the share of diagonal elements of  a 46*46 matrix.

We could define the most central agent as one, which minimizes the distance to other agents. In our specification this would rather correspond to maximizing the nonlinear transformation of distance which we are using. Thus an agent is most central, if the sum of its weights to other agents is highest. 

```{r, echo=FALSE}
head(arrange(data.frame(value = rowSums(Wd)), desc(value)))
```

Maryland is most central agent. It could be that since multiple small regions from around Maryland are included, Maryland has very small distance to them and thus its inverse is large, contributing a lot to maximization of criterion made up above. Thus most central agent is one which has many close neighbors. From the table above we see that other important agents are District of Columbia, Massachusetts and Rhode Island.

We get similar results when using eigenvector centrality:
```{r, echo=FALSE}
G <- graph_from_adjacency_matrix(
  Wd,
  mode = c("undirected"),
  weighted = TRUE,
)

ec <- data.frame(state=cigar_states$Name, ec=eigen_centrality(G)$vector) %>%
      arrange(desc(ec))

knitr::kable(ec, caption = "Eigenvector Centrality")

```





# Exercise B
```{r, eval=FALSE}
setwd("~/Desktop/GITHUB/spatial_econ/data/03_assignment/dataset")

raster_Africa <- read_sf("~/Desktop/GITHUB/spatial_econ/data/03_assignment/dataset/raster_Africa.shp")

geoconflict_main <- read_dta("~/Desktop/GITHUB/spatial_econ/data/03_assignment/dataset/geoconflict_main.dta")

intersect_coord <- read_dta("~/Desktop/GITHUB/spatial_econ/data/03_assignment/dataset/intersect_coord.dta")
```

## Unit of Observation
```{r, echo = FALSE}
area <- st_area(raster_Africa)

raster_Africa %>%
  mutate(area = st_area(geometry))

data <- data.frame(Cells = c("Min", "Mean", "Median", "Max"), Stats = c(min(area), mean(area), median(area), max(area)))

kable(data)
```
The unit of observation are cells in a raster representing a 1×1 degree latitude longitude grid cover. At the equator this corresponds to a side length of 110 km. The areal extension of the cells varies with latitude. Further away from the equator, the area of a cell decreases. 
The table shows the area of the cells. The smallest cell has an area of about 97 857 $km^{2}$, the largest 12 364 $km^{2}$. On average the size of the cells is 11 900 $km^{2}$.  Thus the gap between the smallest and largest cell amounts to about 20%.
They differ because of the distortions induced by the projection of the surface of the earth, onto a 2 dimensional raster grid. 

## Interpretation of Coefficients

## Replication

```{r}
nblist <- poly2nb(raster_Africa, queen = TRUE)

nb.dist.band <- dnearneigh(raster_Africa, 0, 180)

nblist <- dnearneigh(x = st_centroid(raster_Africa), d1 = 0, d2 = 180, longlat = TRUE)

nbw <- nb2listw(nblist, style = "B", zero.policy = TRUE)

weightmatrix <- listw2mat(nbw)


# Defining the binary contiguity matrix with a distance cutoff of 180km

library(units)

# Setting a 180 km cutoff
dist_matrix <- st_distance(raster_Africa)

distance_threshold <- set_units(180000, "m")  # 180,000 meters

contiguity_matrix <- as.matrix(dist_matrix) <= distance_threshold  # distance in meters
binary_matrix <- ifelse(contiguity_matrix, 1, 0)

# Remove diagonal elements to avoid self-neighboring
diag(binary_matrix) <- 0

# Dynamic spatial panel model using maximum likelihood
model <- spml(ANY_EVENT_ACLED ~ SPEI4pg + GSmain_ext_SPEI4pg +W_L2_GSmain_ext_SPEI4pg, 
              data = geoconflict_main, 
              index = c("cell", "year"), 
              listw = nbw, 
              model = "lag", 
              effect = "random", 
              method = "ML")
summary(model)

res2  <- blmpSDPD(formula = "ANY_EVENT_ACLED ~ SPEI4pg + GSmain_ext_SPEI4pg",
                 data = geoconflict_main,
                 W = binary_matrix,
                 model = list("sar", "sdm", "sem", "sdem"),
                 index = c("cell","year"),
                 model = list("sdm"),
                 effect = "twoways", dynamic = TRUE)
res2

# Convert DataFrame to pdata.frame for plm package
pdata <- pdata.frame(df, index = c("id", "time"))

# Create a spatial weights matrix (W)
# For example, using queen contiguity:
coordinates <- as.matrix(df[, c("longitude", "latitude")])
nb <- poly2nb(coordinates, queen = TRUE)
W <- nb2listw(nb, style = "W", zero.policy = TRUE)


listw <- mat2listw(binary_matrix, style = "W", zero.policy = TRUE)


blmpSDPD(ANY_EVENT_ACLED ~ SPEI4pg + L1_SPEI4pg + L2_SPEI4pg, index = c("cell", "year"), dynamic = TRUE, W = listw, data = geoconflict_main)


reg6 <- lagsarlm(ANY_EVENT_ACLED ~ SPEI4pg + GSmain_ext_SPEI4pg, data = geoconflict_main, zero.policy = TRUE, weightmatrix, type="mixed")
summary(reg6)

summary(impacts(COL.SLX))
```