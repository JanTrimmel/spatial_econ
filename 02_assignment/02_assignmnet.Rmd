---
title: '**Spatial Economics -- Assignment 2**'
author: 
  - "Gustav Pirich (h11910449)"
  - "Peter Prlleshi ()"
  - "Filip Lukijanovic ()"
date: "April 2, 2024"
output: 
  pdf_document:
    toc: true
    includes:
      in_header: !expr file.path("~/Desktop/GITHUB/spatial_econ/helper/wraper_code.tex")
header-includes: 
  - \usepackage{tcolorbox}
  - \usepackage[default]{lato}
papersize: a4
geometry: margin = 2cm
urlcolor: DarkOrchid!65!black
---

```{r, setup, include = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(showtext)
showtext_auto()

p_load(sf, magrittr, tidyverse, tmap, viridis, spdep, igraph, generics, stargazer, knitr, kableExtra, haven)
```

\vspace{2em}

\begin{tcolorbox}
\centering \itshape The code that was used in compiling the assignment is available on GitHub at \url{https://github.com/gustavpirich/spatial_econ/blob/main/02_assignment/02_assignmnet.Rmd}.
\end{tcolorbox}

\newpage

# Exercise A

```{r, echo = FALSE}
#reading in spatial dimension of productivity growth
load("~/Desktop/GITHUB/spatial_econ/data/02_assignmnet/export/data1.rda")

#reading in Shapefile of EU-27
EU27 <- read_sf("~/Desktop/GITHUB/spatial_econ/data/02_assignmnet/export/EU27.shp")

# we can also exclude all oversea territories
overseas <- c("FRY1", "FRY2", "FRY3", "FRY4", "FRY5", "FRZZ", 
              "PT20", "PT30", "PTZZ", 
              "ES70", "ESZZ", 
              "NO0B", "NOZZ")

east_germany_nuts2 <- c("DE40", "DE80", "DED3", "DED2", "DED1","DE42", "DE41", "DE30", "DED5", "DEE0", "DEG0", "DEE3", "DEE2", "DEE1")

EU27 <- EU27[! EU27$Id %in% overseas, ]
  
data1 <- data1[! data1$IDb %in% overseas, ]

data_1 <- data1 %>%
  filter(substr(IDb, 1, 2) %in% c("AT", "DE", "IT", "PT", "FR", "ES")) %>%
  select(IDb, pr80b, pr103b, lninv1b, lndens.empb) %>%
  rename("Id" = "IDb") %>%
  filter(!Id %in% east_germany_nuts2)

data_1$prod_growth <- 100*((data_1$pr103b - data_1$pr80b) / data_1$pr80b)

EU27 <- EU27 %>%
  filter(substr(Id, 1, 2) %in% c("AT", "DE", "IT", "PT", "FR", "ES")) %>%
  filter(!Id %in% east_germany_nuts2) %>%
  left_join(data_1, by = c("Id"))

```
## Calculate the growth rate of productivity from 1980 to 2013 and create a map that shows the productivity growth for each region. 

The map shows the productivity growth rates in NUTS-2 regions for the selected countries. We can see that many regions especially in West Germany, Austria, and France exhibited negative productivity growth over the selected period. Notably, Portugal's productivity has been growing the fastest. We suspect that the negative growth rates can be explained by the fact that high-income countries had a high baseline productivity to begin with, while Portugal started from a rather low baseline productivity. Thus we can interpret this as productivity convergence across Europe.

```{r,echo = FALSE}
tm_shape(EU27) +
  tm_polygons("prod_growth", 
              title = "Productivity Growth in %",
              style = "cont", 
              lwd = 2, 
              midpoint =10) +
  tm_legend(position = c("left", "bottom"), legend.outside = TRUE) +
  tm_layout(frame = TRUE, bg.color = "lightblue") 
```

## Generate three different spatial weights matrixes using (i) a distance threshold, (ii) smooth distance-decay, and iii) a contiguity-based measure. 


### (i) Distance Threshold 
First, we create a binary distance threshold spatial weights matrix based. Any region is being assigned a '1' with respect to another region, if it is less than 3 km away. We have chosen this threshold so that every region has a neighbor. We use the nb2mat function from the 'spdep' package. We row-normalize the matrix.

```{r, echo = FALSE}
coords <- st_coordinates(st_centroid(EU27))

#checking the maximum distance as to include all observations which have a matrix   
nb1 <- knn2nb(knearneigh(coords, k = 1))

dist1 <- nbdists(nb1, coords)
summary(unlist(dist1))

distw <- dnearneigh(coords, 0, 3)

#creating matrix based on distance threshold up to 3 kilometers
dist_w_matrix <- nb2mat(distw, style="W", zero.policy=TRUE)
```


### (ii) Smooth-Distance Decay 
Next, we create a spatial weights matrix based on a smooth distance-decay. We use the following simple distance decay function $w_{i, j} (d) = 1/d$. We calculate the weights for each neighboring region based on the k=20 nearest neighbors. We do not row-normalize the matrix.

```{r, echo = FALSE}
k1 <- knearneigh(coords, k=20)
k2 <- knn2nb(k1)

dists <- nbdists(k2, coords)

ids <- lapply(dists, function(d){1/d})

decay_weights_matrix_list <- nb2listw(k2, glist = ids, style = "B", zero.policy = TRUE)

decay_weights_matrix <- listw2mat(decay_weights_matrix_list)
```

### (iii) Contiguity-based measure
Finally, we calculate a contiguity based measure, which we row normalize as well.
```{r, echo = FALSE}
# Create a contiguity-based spatial weights matrix
queen_weights <- poly2nb(EU27, queen = TRUE)

contig_w_matrix <- nb2mat(queen_weights, style="W", zero.policy=TRUE)
```

## Compare the matrices; use your knowledge of graph theory and linear algebra
```{r,echo = FALSE, results = "asis"}
# Convert to igraph objects for graph analysis
graph_dist <- graph_from_adjacency_matrix(dist_w_matrix, mode = "undirected", weighted = TRUE)
graph_decay <- graph_from_adjacency_matrix((decay_weights_matrix), mode = "undirected", weighted = TRUE)
graph_contig <- graph_from_adjacency_matrix(contig_w_matrix, mode = "undirected", weighted = TRUE)

# Function to summarize graph properties
summarize_graph <- function(g) {
  cat("Number of vertices:", vcount(g), "\n")
  cat("Number of edges:", ecount(g), "\n")
  cat("Average path length:", average.path.length(g, directed = FALSE), "\n")
  cat("Graph density:", edge_density(g), "\n")
  cat("Average degree:", mean(degree(g)), "\n")
  
  # Compute Eigenvector Centrality
  ec <- eigen_centrality(g)
  cat("Max Eigenvector Centrality:", max(ec$vector), "\n")
  cat("Min Eigenvector Centrality:", min(ec$vector), "\n")
  cat("Average Eigenvector Centrality:", mean(ec$vector), "\n")
  
  # Identify the most central unit
  max_centrality_index <- which.max(ec$vector)
  most_central_unit <- V(g)[max_centrality_index]
  cat("Most Central Unit (Vertex ID):", as.numeric(most_central_unit), "\n")
}


# Analyze graph properties
cat("Distance Threshold Graph:\n")
summarize_graph(graph_dist)
cat("\nSmooth Distance-Decay Graph:\n")
summarize_graph(graph_decay)
cat("\nContiguity-Based Graph:\n")
summarize_graph(graph_contig)
```
We compare the matrices based on a set of characteristics. We compare the row-normalized matrices for the queen contiguity and distance threshold matrix. Note that normalization procedure does not preserve the structure of the network. 

**Number of edges**

The Smooth Distance-Decay Graph has the most edges (1266). The Distance Threshold Graph has fewer edges (514) than the Smooth Distance-Decay Graph, implying stricter criteria for edge creation based on a fixed distance threshold. The Contiguity-Based Graph has the fewest edges (222), since only directly contiguous or neighboring entities are connected, leading to a more sparse graph structure.

**Average path length**

The Contiguity-Based Graph has the highest average path length (1.2888), reflecting the sparse connectivity where nodes are less directly connected.
The Distance Threshold Graph has a medium average path length (0.6751).
The Smooth Distance-Decay Graph has the lowest average path length (0.4933), indicative of a denser network where nodes are more directly accessible to one another.

**Graph density**

Consistent with the number of edges, the Smooth Distance-Decay Graph is the densest (0.2410), followed by the Distance Threshold Graph (0.0978), with the Contiguity-Based Graph being the least dense (0.0423).

**Average degree**

Again, the Smooth Distance-Decay Graph shows the highest average degree (24.5825), the Distance Threshold Graph shows a medium degree (9.9806), and the Contiguity-Based Graph has the lowest (4.3107).

**Minimum Eigenvector Centrality**

The Contiguity-Based Graph shows the most significant variation in centrality (minimum near zero), reflecting a few very poorly connected nodes, or nodes that only connect to other low-influence nodes. The Smooth Distance-Decay Graph and the Distance Threshold Graph have higher minimum values, indicating a more uniform distribution of node influence.

**Average Eigenvector Centrality**

Higher on average in the Smooth Distance-Decay Graph (0.2837), suggesting that, on average, nodes are better positioned or more influential within the network.
It's lowest in the Contiguity-Based Graph (0.0898), consistent with its sparse and uneven connectivity.

Looking at the most central unit through eigenvector centrality shows that different nodes are identified as most central in each graph, reflecting the impact of the underlying connection logic on the perceived importance or centrality of nodes.


## Plot the matrix
We now plot the three spatial weight matrices. We see that the distance decay weight matrix is symmetric. The distance decay matrix is 
```{r, echo = FALSE, fig.align = 'center', fig.width=5, fig.height=4}
lattice::levelplot((dist_w_matrix), main="Distance Threshold Spatial Weights Matrix",
scales = list(x = list(at = c(20, 40, 60, 80, 100),
                       labels = c(20, 40, 60, 80, 100))))

lattice::levelplot((decay_weights_matrix), main="Smooth Distance-Decay Spatial Weights Matrix",
scales = list(x = list(at = c(20, 40, 60, 80, 100),
                       labels = c(20, 40, 60, 80, 100))))

lattice::levelplot((contig_w_matrix), main="Contiguity-Based Spatial Weights Matrix",
scales = list(x = list(at = c(20, 40, 60, 80, 100),
                       labels = c(20, 40, 60, 80, 100))))
```
## Try to visualize the network they represent

Let us first visualize the distance based spatial matrix. The first plot shows the map of Europe and the blue lines indicate the connections. The map shows the connectivity in Europe based on the distance threshold. 

The second map visualizes the network based on the distance decay matrix. However, the edges do not display the intensity of connections, but just the connectivity to neighboring regions. 

The last map displays the queen contiguity based measure. The islands in the middle sea are not being counted as neighbors. This should caution the use of this network, as it seems implausible that Siciliy for example is not connected to the mainland Italian provinces.  
```{r,echo = FALSE, fig.width=9, fig.height=13, fig.align='center'}
par(mfrow = c(3, 1), las=1)

plot(EU27$geometry, border = "darkgrey", main = "Distance Threshold")
plot(distw, coords, add=TRUE, col="blue", pch = 19, cex = 0.6)

plot(EU27$geometry, border = "darkgrey", main = "Distance Decay")
plot(decay_weights_matrix_list, coords, add=TRUE, col= "green", pch = 19, cex = 0.6)

plot(EU27$geometry, border = 'darkgrey', main = "Queen Contiguity") 
plot(queen_weights, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## Compute a suitable measure of spatial autocorrelation for productivity growth using these matrices. Point out differences, if there are any. 

We calculate Global Moran's I as a measure of spatial autocorrelation for all three spatial weight matrices.  All three matrices display the strong positive spatial autocorrelation between 0.62 - 0.54, which are all highly statistically significant with p-values < 0.01. Thus there is strong evidence for the presence of sizeable levels of spatial autocorrelation. This result is robust to the choice of the spatial weights matrix. 
```{r,echo = FALSE}
# Convert the matrix to a listw object
l_dist_w_matrix <- mat2listw(dist_w_matrix, style = "B", zero.policy = TRUE)

l_decay_weights_matrix <- mat2listw(decay_weights_matrix, zero.policy = TRUE, style = "B")

l_contig_w_matrix <- mat2listw(contig_w_matrix, zero.policy = TRUE, style = "W")

# Compute Global Moran's I
moran_result_dist <- moran.test((EU27$prod_growth), listw = l_dist_w_matrix)

moran_result_decay <- moran.test((EU27$prod_growth), listw = l_decay_weights_matrix)

moran_result_contig <- moran.test((EU27$prod_growth), listw = l_contig_w_matrix)

# Create a data frame to hold the summarized results
moran_summary <- data.frame(
  Test = c("Distance Threshold", "Smooth Distance-Decay", "Contiguity-Based"),
  Moran_I = c(moran_result_dist$estimate["Moran I statistic"], 
              moran_result_decay$estimate["Moran I statistic"], 
              moran_result_contig$estimate["Moran I statistic"]),
  Expectation = c(moran_result_dist$estimate["Expectation"], 
                  moran_result_decay$estimate["Expectation"], 
                  moran_result_contig$estimate["Expectation"]),
  Variance = c(moran_result_dist$estimate["Variance"], 
               moran_result_decay$estimate["Variance"], 
               moran_result_contig$estimate["Variance"]),
  p_value = c(moran_result_dist$p.value, 
              moran_result_decay$p.value, 
              moran_result_contig$p.value)
)

# Format and print the table
kable(moran_summary, "latex", digits = 4, booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down")) %>%
  column_spec(1, bold = TRUE, border_right = TRUE) %>%
  column_spec(5, color = ifelse(moran_summary$p_value < 0.05, "red", "black"))
```
## Estimate a linear regression model using OLS. 
We estimate the specified model and obtain the following output.
\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & prod\_growth \\ 
\hline \\[-1.8ex] 
 pr80b & $-$0.253$^{***}$ \\ 
  & (0.025) \\ 
  & \\ 
 lninv1b & 0.032$^{***}$ \\ 
  & (0.008) \\ 
  & \\ 
 lndens.empb & 0.007 \\ 
  & (0.009) \\ 
  & \\ 
 Constant & 0.314$^{***}$ \\ 
  & (0.061) \\ 
  & \\ 
\hline \\[-1.8ex] 
Observations & 103 \\ 
R$^{2}$ & 0.528 \\ 
Adjusted R$^{2}$ & 0.514 \\ 
Residual Std. Error & 0.080 (df = 99) \\ 
F Statistic & 36.983$^{***}$ (df = 3; 99) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 

We observe strong evidence for spatial autocorrelation. This holds for all spatial weights matrices used. The different weighting schemes highlight differnt countries. Thus the neglect fo this spatial dimension might give rise to bias in the OLS estimated coefficients.  

```{r,echo = FALSE, fig.width=9, fig.height=13, fig.align='center'}
sm <- lm(prod_growth ~ pr80b + lninv1b + lndens.empb, EU27)

# Set layout to 2x2 and adjust margins and label orientation
par(mfrow = c(3, 1), las=1)
#stargazer::stargazer(sm, type = "latex")
moran.plot(sm$residuals, l_dist_w_matrix, xlab = "Residuals", ylab = "Spatially Lagged Residuals")

moran.plot(sm$residuals, l_decay_weights_matrix, xlab = "Residuals", ylab = "Spatially Lagged Residuals")

moran.plot(sm$residuals, l_contig_w_matrix, xlab = "Residuals", ylab = "Spatially Lagged Residuals")
```

# Exercise B

## Creating maps
```{r, echo = FALSE}
literacy_Arg_Bra_Par <- read_dta("~/Desktop/GITHUB/spatial_econ/data/02_assignmnet/export/literacy_Arg-Bra-Par.dta", encoding = "ISO-8859-1")

#downloading the respective shapefiles take care of the file paths!!!
gadm41_PRY_0 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_PRY_shp/gadm41_PRY_0.shp")

gadm41_ARG_0 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_ARG_shp/gadm41_ARG_0.shp")

gadm41_BRA_0 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_BRA_shp/gadm41_BRA_0.shp")

gadm41_PRY_1 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_PRY_shp/gadm41_PRY_1.shp")

gadm41_ARG_1 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_ARG_shp/gadm41_ARG_1.shp")

gadm41_BRA_1 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_BRA_shp/gadm41_BRA_1.shp")

dat1 <- rbind(gadm41_BRA_1, gadm41_ARG_1, gadm41_PRY_1)


gadm41_PRY_2 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_PRY_shp/gadm41_PRY_2.shp")

gadm41_ARG_2 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_ARG_shp/gadm41_ARG_2.shp")

gadm41_BRA_2 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_BRA_shp/gadm41_BRA_2.shp")

dat0 <- rbind(gadm41_BRA_0, gadm41_ARG_0, gadm41_PRY_0)


gadm41_BRA_2 %<>%
  filter(NAME_1 %in% c("Rio Grande do Sul"))

gadm41_ARG_2 %<>%
  filter(NAME_1 %in% c("Misiones", "Corrientes"))

gadm41_PRY_2 %<>%
  filter(NAME_1 %in% c("Misiones", "Itapúa"))

dat2 <- rbind(gadm41_BRA_2, gadm41_ARG_2, gadm41_PRY_2)

list_2 <- dat2 %>%
  select(COUNTRY, geometry, NAME_1, NAME_2) %>%
  mutate(country = ifelse(COUNTRY == "Brazil", "BRA", COUNTRY)) %>%
  rename("muni" = "NAME_2") %>%
  mutate(state = ifelse(NAME_1 == "Rio Grande do Sul", "RS", NAME_1)) 


#merging the data
#literacy_Arg_Bra_Par_2 <- left_join(literacy_Arg_Bra_Par_1, list_1, by = c("NAME_2", "COUNTRY"))

literacy_Arg_Bra_Par_2 <- literacy_Arg_Bra_Par %>%
  left_join(list_2, by = c("muni", "state", "country"))
```

```{r, echo = FALSE}
#map2 = tm_shape(literacy_Arg_Bra_Par_2) +
#  tm_fill("literacy") + 
#  tm_borders() +
#  tm_legend(legend.outside = TRUE, position = c("right", "bottom")) + 
#  tm_shape(dat0) + 
#  tm_borders(lwd = 3, col = "black") +
#  tm_layout(frame = FALSE) + 
#  tm_shape(coords_sf) +
#  tm_text("country", size = 1) +
#  tm_layout(frame = FALSE) + 
#  tm_compass(type = "8star") +
#  tm_shape(dat1)+
#  tm_borders()

#map2





# Corrected country name and efficient use of tm_layout
coords <- data.frame(
  country = c("ARGENTINA", "BRAZIL", "PARAGUAY", "URUGUAY"),
  lon = c(-58, -55, -56, -56), # Correct longitudes
  lat = c(-29, -30, -26, -33)  # Correct latitudes
)

# Convert to an sf object
coords_sf <- st_as_sf(coords, coords = c("lon", "lat"), crs = 4326, agr = "constant")

# Updated map visualization
map2 <- tm_shape(literacy_Arg_Bra_Par_2) +
  tm_fill("literacy", palette = "magma") +
  tm_borders() +
  tm_legend(legend.outside = TRUE, position = c("right", "bottom")) + 
  tm_shape(dat0) + 
  tm_borders(lwd = 3.5, col = "black") +
  tm_shape(coords_sf) +
  tm_text("country", size = 1.2) +
  #tm_compass(type = "8star", position = c("right", "top")) +
  tm_layout(frame = FALSE) +
  tm_scale_bar(position = c(0.9, 0.8)) + 
  tm_shape(dat1) +
  tm_borders(lty = 2)

map2
```


We now replicate table 2
```{r}
mod1 <- lm(illiteracy ~ (lati) + (longi) + distmiss + state, data = literacy_Arg_Bra_Par_2)

mod2 <- lm(illiteracy ~ (lati) + (longi) + distmiss + state + coast + river + slope + rugg + alti + tempe + preci + area, data = literacy_Arg_Bra_Par_2)


bra <- literacy_Arg_Bra_Par_2 %>% 
             filter(country == "BRA")

mod3 <- lm(illiteracy ~ (lati) + (longi) + distmiss + mesorregi, data = bra)

mod4 <- lm(illiteracy ~ (lati) + (longi) + distmiss + mesorregi + coast + river + slope + rugg + alti + tempe + preci + area, data = bra)


arg <- literacy_Arg_Bra_Par_2 %>% 
             filter(country == "Argentina")

mod5 <- lm(illiteracy ~ (lati) + (longi) + distmiss, data = arg)

mod6 <- lm(illiteracy ~ (lati) + (longi) + distmiss + coast + river + slope + rugg + alti + tempe + preci + area, data = arg)


par <- literacy_Arg_Bra_Par_2 %>% 
             filter(country == "Paraguay")

mod7 <- lm(illiteracy ~ (lati) + (longi) + distmiss + state, data = par)

mod8 <- lm(illiteracy ~ (lati) + (longi) + distmiss + state + coast + river + slope + rugg + alti + tempe + preci + area, data = par)

stargazer(mod1, mod2, mod3, mod4, mod5, mod6, mod7, mod8)

```
\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcccccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{8}{c}{\textit{Dependent variable:}} \\ 
\cline{2-9} 
\\[-1.8ex] & \multicolumn{8}{c}{illiteracy} \\ 
\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8)\\ 
\hline \\[-1.8ex] 
 lati & 0.556$^{**}$ & 0.072 & 0.359 & 3.206$^{**}$ & 0.043 & $-$6.724$^{**}$ & 3.540$^{**}$ & $-$7.429 \\ 
  & (0.251) & (0.782) & (0.403) & (1.473) & (0.643) & (2.599) & (1.622) & (4.381) \\ 
  & & & & & & & & \\ 
 longi & $-$1.108$^{***}$ & $-$1.007 & $-$1.716$^{***}$ & $-$5.054$^{***}$ & 0.054 & 6.704$^{***}$ & 0.298 & 20.866$^{***}$ \\ 
  & (0.269) & (0.687) & (0.369) & (1.521) & (0.496) & (1.934) & (1.017) & (6.364) \\ 
  & & & & & & & & \\ 
 distmiss & 0.011$^{***}$ & 0.011$^{**}$ & 0.020$^{***}$ & 0.031$^{***}$ & 0.013 & 0.055$^{***}$ & $-$0.035 & $-$0.071$^{**}$ \\ 
  & (0.004) & (0.005) & (0.006) & (0.008) & (0.008) & (0.019) & (0.023) & (0.029) \\ 
  & & & & & & & & \\ 
 stateItapúa & 2.154 & 3.619$^{**}$ &  &  &  &  &  &  \\ 
  & (1.350) & (1.693) &  &  &  &  &  &  \\ 
  & & & & & & & & \\ 
 stateMisiones & 1.017 & 1.297 &  &  &  &  & 0.200 & $-$2.053 \\ 
  & (1.572) & (1.865) &  &  &  &  & (1.481) & (1.661) \\ 
  & & & & & & & & \\ 
 stateMisiones1 & 2.061 & 3.733$^{**}$ &  &  &  &  &  &  \\ 
  & (1.565) & (1.881) &  &  &  &  &  &  \\ 
  & & & & & & & & \\ 
 stateRS & 5.341$^{***}$ & 6.027$^{***}$ &  &  &  &  &  &  \\ 
  & (1.521) & (1.798) &  &  &  &  &  &  \\ 
  & & & & & & & & \\ 
 coast &  & 0.209 &  & $-$3.864$^{**}$ &  & $-$0.764 &  & 21.631$^{***}$ \\ 
  &  & (0.989) &  & (1.848) &  & (2.857) &  & (7.366) \\ 
  & & & & & & & & \\ 
 river &  & 1.465$^{**}$ &  & 1.645$^{**}$ &  & 10.574$^{***}$ &  & $-$4.913 \\ 
  &  & (0.741) &  & (0.802) &  & (2.672) &  & (4.569) \\ 
  & & & & & & & & \\ 
 slope &  & $-$0.00001 &  & 0.00002 &  & $-$0.053$^{*}$ &  & $-$0.071$^{***}$ \\ 
  &  & (0.0002) &  & (0.0002) &  & (0.028) &  & (0.021) \\ 
  & & & & & & & & \\ 
 rugg &  & $-$0.00000 &  & $-$0.00000 &  & 0.001$^{*}$ &  & 0.002$^{***}$ \\ 
  &  & (0.00000) &  & (0.00000) &  & (0.001) &  & (0.001) \\ 
  & & & & & & & & \\ 
 alti &  & 0.006 &  & 0.005 &  & 0.062$^{***}$ &  & 0.038$^{**}$ \\ 
  &  & (0.004) &  & (0.005) &  & (0.011) &  & (0.014) \\ 
  & & & & & & & & \\ 
 tempe &  & 0.058 &  & 0.057 &  & 0.915$^{***}$ &  & 0.842$^{***}$ \\ 
  &  & (0.079) &  & (0.099) &  & (0.208) &  & (0.204) \\ 
  & & & & & & & & \\ 
 preci &  & $-$0.003 &  & $-$0.002 &  & $-$0.019$^{**}$ &  & $-$0.012$^{**}$ \\ 
  &  & (0.002) &  & (0.002) &  & (0.007) &  & (0.005) \\ 
  & & & & & & & & \\ 
 area &  & 0.0001 &  & $-$0.0004 &  & $-$0.0003 &  & 0.002$^{***}$ \\ 
  &  & (0.0002) &  & (0.0003) &  & (0.0002) &  & (0.001) \\ 
  & & & & & & & & \\ 
 mesorregi &  &  & $-$0.418$^{*}$ & $-$0.216 &  &  &  &  \\ 
  &  &  & (0.216) & (0.261) &  &  &  &  \\ 
  & & & & & & & & \\ 
 Constant & $-$40.669$^{***}$ & $-$59.567 & 1,724.668$^{*}$ & 755.296 & 11.554 & 31.195 & 121.370$^{*}$ & 685.427$^{***}$ \\ 
  & (13.191) & (36.199) & (919.888) & (1,111.741) & (20.002) & (72.708) & (60.387) & (208.813) \\ 
  & & & & & & & & \\ 
\hline \\[-1.8ex] 
Observations & 549 & 548 & 467 & 467 & 42 & 42 & 40 & 39 \\ 
R$^{2}$ & 0.042 & 0.073 & 0.056 & 0.095 & 0.099 & 0.695 & 0.145 & 0.652 \\ 
Adjusted R$^{2}$ & 0.029 & 0.047 & 0.048 & 0.071 & 0.028 & 0.583 & 0.047 & 0.491 \\ 
Residual Std. Error & 3.948 (df = 541) & 3.916 (df = 532) & 4.101 (df = 462) & 4.050 (df = 454) & 2.997 (df = 38) & 1.962 (df = 30) & 2.048 (df = 35) & 1.513 (df = 26) \\ 
F Statistic & 3.370$^{***}$ (df = 7; 541) & 2.793$^{***}$ (df = 15; 532) & 6.880$^{***}$ (df = 4; 462) & 3.976$^{***}$ (df = 12; 454) & 1.396 (df = 3; 38) & 6.218$^{***}$ (df = 11; 30) & 1.482 (df = 4; 35) & 4.058$^{***}$ (df = 12; 26) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{8}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 

# Exercise C


